<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Human Ear Engine v2026.01.17-05</title>
    <style>
        body { margin: 0; background: #000; color: white; overflow: hidden; font-family: sans-serif; }
        canvas { display: block; }
        #overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            display: flex; flex-direction: column; justify-content: center; align-items: center;
            background: rgba(2, 2, 10, 0.95); z-index: 100;
        }
        .mode-btn {
            padding: 15px 30px; font-size: 14px; background: #111; color: #00d4ff; 
            border: 2px solid #00d4ff; border-radius: 8px; cursor: pointer; margin: 10px;
        }
        #monitor {
            position: absolute; top: 15px; left: 15px; font-size: 11px;
            background: rgba(0,0,0,0.7); padding: 12px; border-radius: 8px;
            border: 1px solid #333; pointer-events: none; z-index: 50;
        }
        #ver-tag { position: absolute; bottom: 5px; right: 5px; font-size: 9px; color: #333; }
    </style>
</head>
<body>

<div id="overlay">
    <h2 style="letter-spacing: 2px;">PERCEPTION ENGINE v5</h2>
    <button class="mode-btn" onclick="startMic()">START MIC MODE</button>
</div>

<div id="monitor">
    <div style="color: #ff007b; margin-bottom: 5px;">HUMAN PERCEPTION: ACTIVE</div>
    BASS ENERGY: <span id="lowVal">0</span><br>
    TREBLE SENS: <span id="highVal">0</span>
</div>

<div id="ver-tag">ENGINE_ID: 2026.01.17-05</div>
<canvas id="waveCanvas"></canvas>

<script>
const canvas = document.getElementById('waveCanvas');
const ctx = canvas.getContext('2d');
let audioCtx, analyser, dataArray, sourceNode;
let isRunning = false;
let shakeTime = 0;

async function startMic() {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    sourceNode = audioCtx.createMediaStreamSource(stream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 1024;
    sourceNode.connect(analyser);
    dataArray = new Uint8Array(analyser.frequencyBinCount);
    document.getElementById('overlay').style.display = 'none';
    isRunning = true;
    resize();
    animate();
}

// --- A特性補正（近似計算） ---
// 周波数 f に基づいてデシベル補正値を返す
function getAWeighting(f) {
    if (f <= 0) return -100;
    const f2 = f * f;
    const rA = (1486428800 * f2 * f2) / 
               ((f2 + 424.36) * Math.sqrt((f2 + 11599.29) * (f2 + 544496.41)) * (f2 + 1486428800));
    return 2.0 + 20 * Math.log10(rA);
}

function resize() {
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;
}

function animate() {
    if (!isRunning) return;
    requestAnimationFrame(animate);
    analyser.getByteFrequencyData(dataArray);

    const sampleRate = audioCtx.sampleRate;
    const binCount = analyser.frequencyBinCount;

    ctx.save();
    if (shakeTime > 0) {
        ctx.translate((Math.random()-0.5)*10, (Math.random()-0.5)*10);
        shakeTime--;
    }

    ctx.fillStyle = 'rgba(2, 2, 10, 0.25)';
    ctx.fillRect(-20, -20, canvas.width+40, canvas.height+40);

    const barCount = Math.floor(canvas.width / 3);
    const baseY = canvas.height * 0.65;
    const maxIdx = binCount * 0.85;

    ctx.globalCompositeOperation = 'lighter';

    for (let i = 0; i < barCount; i++) {
        const relX = i / barCount;
        const logIdx = Math.floor(1 * Math.pow(maxIdx / 1, relX));
        const freq = (logIdx * sampleRate) / (analyser.fftSize);
        
        let val = dataArray[logIdx];

        // --- 聴感補正の適用 ---
        const weight = getAWeighting(freq);
        // デシベルベースの補正を高さに反映
        // 低音は weight がマイナスに大きくなるため、見た目の高さが抑えられる
        let perceivedVal = val + weight; 
        perceivedVal = Math.max(0, perceivedVal);

        const h = (perceivedVal / 255) * canvas.height * 0.7 * Math.sin(relX * Math.PI) + 2;
        const x = i * 3;
        const hue = 280 + (30 - 280) * relX;

        // メイン描画
        const grd = ctx.createLinearGradient(x, baseY - h, x, baseY);
        grd.addColorStop(0, `hsla(${hue}, 100%, 75%, 0.8)`);
        grd.addColorStop(1, `hsla(${hue}, 80%, 30%, 0)`);
        ctx.fillStyle = grd;
        ctx.fillRect(x, baseY - h, 2, h);

        // 低音の物理振動判定（補正前の純粋なエネルギーで判定）
        if (relX < 0.1 && val > 210) shakeTime = 5;
    }
    ctx.restore();
}
window.addEventListener('resize', resize);
</script>
</body>
</html>
